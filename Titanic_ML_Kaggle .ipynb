{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Competitions Kaggle\n",
    "![image](https://user-images.githubusercontent.com/45148200/50421918-9dd08e80-0844-11e9-8ea8-1a62067d3c35.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mamoun\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesRegressor\n",
    "from sklearn import cross_validation\n",
    "import re\n",
    "import operator\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction the data and fixing the key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", dtype={\"Age\": np.float64} )\n",
    "test = pd.read_csv(\"test.csv\", dtype={\"Age\": np.float64})\n",
    "\n",
    "target = train[\"Survived\"].values\n",
    "full = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "What is thi importance of Feature Engineering ?\n",
    "![image](https://user-images.githubusercontent.com/45148200/50422104-4c75ce80-0847-11e9-9665-63d2e37660aa.png)\n",
    "\n",
    "\n",
    "Therefore we must spent most of our time trying to build the best features in order to get the maximum informations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name\n",
    "\n",
    "- Surname\n",
    "- NameLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['surname'] = full[\"Name\"].apply(lambda x: x.split(',')[0].lower())\n",
    "full[\"NameLength\"] = full[\"Name\"].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Title\n",
    "A lady has higher chance to be rescued and thus survive same for Master ...\n",
    "\n",
    "- Get the title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full[\"Title\"] = full[\"Name\"].apply(lambda x: re.search(' ([A-Za-z]+)\\.',x).group(1))\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 2, \"Mme\": 3,\"Don\": 9,\"Dona\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "full[\"TitleCat\"] = full.loc[:,'Title'].map(title_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family\n",
    "If the person is alone he won't be preoccuped by others which means the chance for him to survive are higher.\n",
    "\n",
    "- We split the Family size columns into 4 categories \n",
    "    - 0 = Alone\n",
    "    - 1 = Small Family\n",
    "    - 2 = Medium Family\n",
    "    - 3 = Large Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full[\"FamilySize\"] = full[\"SibSp\"] + full[\"Parch\"] + 1\n",
    "full[\"FamilySize\"] = pd.cut(full[\"FamilySize\"], 4, labels=[0,1,2,3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embarked\n",
    "Here instead of using get_dummies  we split this variables in 3 categories : S, Q, C that we map with 0, 1, 2. Therefore this another way to map a columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full[\"Embarked\"] = pd.Categorical(full.Embarked).codes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fare\n",
    "This an other way to do what we did with the Family size but its more manual. We are the ones fixing the thresholds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full[\"Fare\"] = full[\"Fare\"].fillna(8.05)\n",
    "full.loc[ full['Fare'] <= 7.91, 'Fare']      = 0\n",
    "full.loc[(full['Fare'] > 7.91) & (full['Fare'] <= 14.454), 'Fare'] = 1\n",
    "full.loc[(full['Fare'] > 14.454) & (full['Fare'] <= 31), 'Fare']   = 2\n",
    "full.loc[ full['Fare'] > 31, 'Fare']= 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex \n",
    "We map this columns the commun way\n",
    "\n",
    "- 0 = Female\n",
    "- 1 = Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['Sex'] = full['Sex'].map( {'female': 0, 'male': 1} ).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CabinCat \n",
    "It might not be clear, what we are doing here is first fill the Cabin columuns but in a new columns so for each row  where there was a NaNs in Cabin there will be a 0 in the adequate row if this new variable. Then we map the the Cabin varibles in this new one and that on the first character of the Cabin number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['CabinCat'] = pd.Categorical(full.Cabin.fillna('0').apply(lambda x: x[0])).codes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The Cabin Type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_type_cabine(cabine):\n",
    "  \n",
    "    cabine_search = re.search('\\d+', cabine)\n",
    " \n",
    "    if cabine_search:\n",
    "        num = cabine_search.group(0)\n",
    "        if np.float64(num) % 2 == 0:\n",
    "            return '2'\n",
    "        else:\n",
    "            return '1'\n",
    "    return '0'\n",
    "full[\"Cabin\"] = full[\"Cabin\"].fillna(\" \")\n",
    "\n",
    "full[\"CabinType\"] = full[\"Cabin\"].apply(get_type_cabine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age\n",
    "Here we deal with the age. If we stick to what to common knowledges tells us in catastroph time such as this the children, old people and womens are the first to get rescued.Thus we divide this column like this:\n",
    "\n",
    "- Child if <14\n",
    "- Old female or male > 60\n",
    "- 14< Male or female < 60\n",
    "\n",
    "After this we use the get_dummies that gives us a column for every case here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_age = 14\n",
    "old_age=60\n",
    "def get_person(passenger):\n",
    "    age, sex = passenger\n",
    "    if (age < child_age):\n",
    "        return 'child'\n",
    "    elif (sex == 0  ):\n",
    "        if (age>old_age):\n",
    "            return 'female_adult_old'\n",
    "        else:\n",
    "            return 'female_adult'\n",
    "    elif (sex == 1  ):\n",
    "        if (age>old_age):\n",
    "            return 'male_adult_old'\n",
    "        else:\n",
    "            return 'male_adult'\n",
    "full = pd.concat([full, pd.DataFrame(full[['Age', 'Sex']].apply(get_person, axis=1), columns=['person'])],axis=1)\n",
    "full = pd.concat([full,pd.get_dummies(full['person'])],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ticket\n",
    "This one was i thing a really elaborated feature research. I didn't do it myself I saw it on a kernel on Kaggle.\n",
    "\n",
    "Basically what is done here is according relevance to the ticket numbers as it may help knowing if the person is next to an rescue area.\n",
    "Therefore for each ticket we determine for whom it belongs : \n",
    "\n",
    "- A male or A female\n",
    "- A lonely person \n",
    "- A survivor or a dead person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ticket = pd.DataFrame(full[\"Ticket\"].value_counts())\n",
    "table_ticket.rename(columns={'Ticket':'Ticket_Members'}, inplace=True)\n",
    "\n",
    "table_ticket['Ticket_perishing_women'] = full.Ticket[(full.female_adult == 1.0) \n",
    "                                    & (full.Survived == 0.0) \n",
    "                                    & ((full.Parch > 0) | (full.SibSp > 0))].value_counts()\n",
    "table_ticket['Ticket_perishing_women'] = table_ticket['Ticket_perishing_women'].fillna(0)\n",
    "table_ticket['Ticket_perishing_women'][table_ticket['Ticket_perishing_women'] > 0] = 1.0 \n",
    "\n",
    "table_ticket['Ticket_surviving_men'] = full.Ticket[(full.male_adult == 1.0) \n",
    "                                    & (full.Survived == 1.0) \n",
    "                                    & ((full.Parch > 0) | (full.SibSp > 0))].value_counts()\n",
    "table_ticket['Ticket_surviving_men'] = table_ticket['Ticket_surviving_men'].fillna(0)\n",
    "table_ticket['Ticket_surviving_men'][table_ticket['Ticket_surviving_men'] > 0] = 1.0 \n",
    "\n",
    "table_ticket[\"Ticket_Id\"]= pd.Categorical(table_ticket.index).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ticket[\"Ticket_Id\"][table_ticket[\"Ticket_Members\"] < 3 ] = -1\n",
    "table_ticket[\"Ticket_Members\"] = pd.cut(table_ticket[\"Ticket_Members\"], bins=[0,1,4,20], labels=[0,1,2])\n",
    "\n",
    "full = pd.merge(full, table_ticket, left_on=\"Ticket\",right_index=True,how='left', sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_surname = pd.DataFrame(full[\"surname\"].value_counts())\n",
    "table_surname.rename(columns={'surname':'Surname_Members'}, inplace=True)\n",
    "\n",
    "table_surname['Surname_perishing_women'] = full.surname[(full.female_adult == 1.0) \n",
    "                                    & (full.Survived == 0.0) \n",
    "                                    & ((full.Parch > 0) | (full.SibSp > 0))].value_counts()\n",
    "table_surname['Surname_perishing_women'] = table_surname['Surname_perishing_women'].fillna(0)\n",
    "table_surname['Surname_perishing_women'][table_surname['Surname_perishing_women'] > 0] = 1.0 \n",
    "\n",
    "table_surname['Surname_surviving_men'] = full.surname[(full.male_adult == 1.0) \n",
    "                                    & (full.Survived == 1.0) \n",
    "                                    & ((full.Parch > 0) | (full.SibSp > 0))].value_counts()\n",
    "table_surname['Surname_surviving_men'] = table_surname['Surname_surviving_men'].fillna(0)\n",
    "table_surname['Surname_surviving_men'][table_surname['Surname_surviving_men'] > 0] = 1.0 \n",
    "\n",
    "table_surname[\"Surname_Id\"]= pd.Categorical(table_surname.index).codes\n",
    "# compress under 3 members into one code.\n",
    "table_surname[\"Surname_Id\"][table_surname[\"Surname_Members\"] < 3 ] = -1\n",
    "\n",
    "table_surname[\"Surname_Members\"] = pd.cut(table_surname[\"Surname_Members\"], bins=[0,1,4,20], labels=[0,1,2])\n",
    "\n",
    "full = pd.merge(full, table_surname, left_on=\"surname\",right_index=True,how='left', sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training & testing set\n",
    "Here we operate an age processing as well as constitute a the training & testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classers = ['Fare','Parch','Pclass','SibSp','TitleCat', \n",
    "'CabinCat','Sex', 'Embarked', 'FamilySize', 'NameLength','Ticket_Members','Ticket_Id']\n",
    "etr = RandomForestRegressor(n_estimators=200,max_depth=15)\n",
    "X_train = full[classers][full['Age'].notnull()]\n",
    "Y_train = full['Age'][full['Age'].notnull()]\n",
    "X_test = full[classers][full['Age'].isnull()]\n",
    "etr.fit(X_train,np.ravel(Y_train))\n",
    "age_preds = etr.predict(X_test)\n",
    "full['Age'][full['Age'].isnull()] = age_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features \n",
    "Finally , we regroup every relevant feature for the training and we evaluate the importance of every feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features importance :\n",
      "68.85 Sex\n",
      "66.05 male_adult\n",
      "59.96 female_adult\n",
      "26.22 TitleCat\n",
      "24.60 Pclass\n",
      "24.60 Pclass\n",
      "23.69 NameLength\n",
      "18.73 Fare\n",
      "17.75 CabinCat\n",
      "17.41 Ticket_surviving_men\n",
      "16.28 CabinType\n",
      "13.54 Ticket_perishing_women\n",
      "13.16 Surname_surviving_men\n",
      "10.36 Surname_perishing_women\n",
      "6.94 Embarked\n",
      "5.27 Ticket_Members\n",
      "3.77 child\n",
      "1.94 male_adult_old\n",
      "1.83 Parch\n",
      "1.55 female_adult_old\n",
      "1.41 Age\n",
      "1.19 FamilySize\n",
      "1.07 Ticket_Id\n",
      "0.73 Surname_Members\n",
      "0.53 SibSp\n"
     ]
    }
   ],
   "source": [
    "features = ['Sex','Age','female_adult','male_adult','female_adult_old','male_adult_old', 'child','TitleCat', 'Pclass',\n",
    "'Pclass','Ticket_Id','NameLength','CabinType','CabinCat', 'SibSp', 'Parch',\n",
    "'Fare','Embarked','Surname_Members','Ticket_Members','FamilySize',\n",
    "'Ticket_perishing_women','Ticket_surviving_men',\n",
    "'Surname_perishing_women','Surname_surviving_men']\n",
    "\n",
    "train = full[0:891].copy()\n",
    "test = full[891:].copy()\n",
    "\n",
    "selector = SelectKBest(f_classif, k=len(features))\n",
    "selector.fit(train[features], target)\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "indices = np.argsort(scores)[::-1]\n",
    "print(\"Features importance :\")\n",
    "for f in range(len(scores)):\n",
    "    print(\"%0.2f %s\" % (scores[indices[f]],features[indices[f]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training & predicition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.970 (+/- 1.37) [RFC Cross Validation]\n",
      "Accuracy: 95.960            [RFC full test]\n",
      "1. feature 2 (10.304259) Age\n",
      "2. feature 12 (9.658326) NameLength\n",
      "3. feature 8 (9.546538) TitleCat\n",
      "4. feature 1 (8.889116) Sex\n",
      "5. feature 22 (7.680901) Ticket_perishing_women\n",
      "6. feature 24 (6.822472) Surname_perishing_women\n",
      "7. feature 4 (6.572493) male_adult\n",
      "8. feature 3 (6.191833) female_adult\n",
      "9. feature 23 (4.390043) Ticket_surviving_men\n",
      "10. feature 10 (3.505881) Pclass\n",
      "11. feature 9 (3.498047) Pclass\n",
      "12. feature 20 (3.315192) Ticket_Members\n",
      "13. feature 17 (2.959209) Fare\n",
      "14. feature 14 (2.712229) CabinCat\n",
      "15. feature 25 (2.496848) Surname_surviving_men\n",
      "16. feature 19 (2.137385) Surname_Members\n",
      "17. feature 18 (1.901887) Embarked\n",
      "18. feature 13 (1.901883) CabinType\n",
      "19. feature 15 (1.450315) SibSp\n",
      "20. feature 11 (1.330757) Ticket_Id\n",
      "21. feature 7 (0.816043) child\n",
      "22. feature 16 (0.750141) Parch\n",
      "23. feature 6 (0.587522) male_adult_old\n",
      "24. feature 21 (0.489366) FamilySize\n",
      "25. feature 5 (0.091315) female_adult_old\n",
      "The end ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rfc = RandomForestClassifier(n_estimators=5000, min_samples_split=4, class_weight={0:0.5,1:0.255})\n",
    "xgb = GradientBoostingClassifier(n_estimators=5000,learning_rate=0.1,max_depth=10)\n",
    "\n",
    "\n",
    "kf = cross_validation.KFold(train.shape[0], n_folds=4, random_state=1)\n",
    "\n",
    "scores = cross_validation.cross_val_score(xgb, train[features], target, cv=kf)\n",
    "print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean()*100, scores.std()*100, 'RFC Cross Validation'))\n",
    "rfc.fit(train[features], target)\n",
    "score = rfc.score(train[features], target)\n",
    "print(\"Accuracy: %0.3f            [%s]\" % (score*100, 'RFC full test'))\n",
    "importances = rfc.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(len(features)):\n",
    "    print(\"%d. feature %d (%f) %s\" % (f + 1, indices[f]+1, importances[indices[f]]*100, features[indices[f]]))\n",
    "\n",
    "\n",
    "rfc.fit(train[features], target)\n",
    "predictions = rfc.predict(test[features])\n",
    "\n",
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_prediction = pd.DataFrame(predictions, PassengerId, columns = [\"Survived\"])\n",
    "\n",
    "my_prediction.to_csv(\"submission3_1.csv\", index_label = [\"PassengerId\"])\n",
    "\n",
    "print(\"The end ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
